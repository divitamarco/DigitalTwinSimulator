# Overview

Il progetto **Digital Twin Simulator** √® una piattaforma di **prototipazione rapida di Digital Twin 3D** che integra **Computer Graphics**, **Deep Learning** e **Mixed Reality**.
L‚Äôobiettivo √® permettere la **generazione automatica di modelli 3D a partire da immagini 2D**, la loro **visualizzazione interattiva in Unity**, e l‚Äô**interazione tramite XR (grab, move, inspect)**.

Il sistema √® pensato come una **pipeline end-to-end** che collega:

* segmentazione dell‚Äôimmagine (SAM),
* generazione del modello 3D (Stable Fast 3D),
* rendering e interazione in ambiente Unity (XR).

---

## Pipeline di funzionamento

1. **Selezione immagine 2D**

   * L‚Äôutente seleziona un‚Äôimmagine tramite interfaccia Unity.

2. **Segmentazione**

   * L‚Äôimmagine viene inviata al backend Flask.
   * Il modello **SAM (Segment Anything Model)** individua l‚Äôoggetto principale.

3. **Generazione del modello 3D**

   * Stable Fast 3D genera un modello tridimensionale coerente.
   * Il modello viene esportato in formato **GLB**.

4. **Caricamento in Unity**

   * Unity carica dinamicamente il GLB.
   * Il modello viene inserito nella gerarchia senza distruggere i prefab XR.

5. **Interazione XR**

   * Il modello √® immediatamente **grabbable** e manipolabile.
   * Supporto a Ray / Hand Interaction.

---

## Tecnologie utilizzate

| Componente           | Tecnologia                   |
| -------------------- | ---------------------------- |
| **Game Engine**      | Unity                        |
| **Frontend**         | C#                           |
| **Backend**          | Python (Flask)               |
| **Segmentazione**    | SAM (Segment Anything Model) |
| **Generazione 3D**   | Stable Fast 3D               |
| **Formato Modelli**  | GLB / glTF                   |
| **XR / Interaction** | Meta XR SDK                  |

---

## Struttura delle cartelle

```plaintext
computer_graphics/
‚îú‚îÄ‚îÄ flask_server/
‚îÇ   ‚îú‚îÄ‚îÄ app.py
‚îÇ   ‚îú‚îÄ‚îÄ sam_utils.py
‚îÇ   ‚îú‚îÄ‚îÄ stable3d_utils.py
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îî‚îÄ‚îÄ models/
‚îÇ       ‚îî‚îÄ‚îÄ sam_vit_h_4b8939.pth
‚îú‚îÄ‚îÄ stable-fast-3d/
‚îÇ   ‚îú‚îÄ‚îÄ texture_baker/
‚îÇ   ‚îú‚îÄ‚îÄ uv_unwrapper/
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ unity_project/
‚îÇ   ‚îú‚îÄ‚îÄ Scenes/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DigitalTwin.unity
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Scripts/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ TwinWorkflow.cs
‚îî‚îÄ‚îÄ README.md
```

---

## Modelli di Deep Learning utilizzati

Il progetto utilizza **due modelli di Deep Learning distinti**, integrati in una pipeline sequenziale:

1. **SAM ‚Äì Segment Anything Model** per la segmentazione dell‚Äôoggetto.
2. **Stable Fast 3D** per la generazione automatica del modello tridimensionale.

Entrambi i modelli sono eseguiti **localmente**, senza dipendenze da servizi cloud esterni.

---

## Segment Anything Model (SAM)

Il **Segment Anything Model (SAM)** viene utilizzato per isolare automaticamente l‚Äôoggetto di interesse all‚Äôinterno dell‚Äôimmagine 2D di input.
La segmentazione migliora significativamente la qualit√† della ricostruzione 3D, riducendo il rumore introdotto dallo sfondo.

### Repository ufficiale

üîó [https://huggingface.co/HCMUE-Research/SAM-vit-h/blob/main/sam_vit_h_4b8939.pth]

## Stable Fast 3D ‚Äì Generazione del modello 3D

La ricostruzione tridimensionale avviene tramite **Stable Fast 3D**, un framework sviluppato da **Stability AI** per la generazione rapida di mesh 3D a partire da immagini segmentate.

### Repository ufficiale

üîó [https://github.com/Stability-AI/stable-fast-3d](https://github.com/Stability-AI/stable-fast-3d)

### Installazione di Stable Fast 3D

> **NB:** Stable Fast 3D richiede **Python 3.9** (testato).
> Versioni successive possono causare errori di build su Windows.

> **NB:** Stable Fast 3D richiede il login a HuggingFace: [https://huggingface.co]

> Crea un token di accesso con permessi di lettura.

> Esegui ```bash huggingface-cli login ``` nell‚Äôambiente e inserisci il token.

1. Clonare il repository:

```bash
git clone https://github.com/Stability-AI/stable-fast-3d.git
cd stable-fast-3d
```

2. Creare e attivare l‚Äôambiente virtuale:

```bash
python3.9 -m venv venv
source venv/bin/activate   # Linux / WSL
venv\Scripts\activate      # Windows
```

3. Installare PyTorch (obbligatorio):

```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

4. Installare le dipendenze:

```bash
pip install -r requirements.txt --no-build-isolation
```

L‚Äôoutput della pipeline √® un file **GLB**, successivamente caricato dinamicamente in Unity.

---

## Setup del Backend (Flask + Stable Fast 3D)

> **NB:** Il backend √® stato sviluppato e testato su **Windows**, con Python **3.9**.
> **NB:** Il frontend √® stato sviluppato e testato su **Unity**, con Meta XR SDK **77.0.0**.
> Versioni pi√π recenti potrebbero causare problemi di compatibilit√†.

1Ô∏è‚É£ Creazione ambiente virtuale

```bash
python3.9 -m venv venv
```

2Ô∏è‚É£ Installazione PyTorch

```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

3Ô∏è‚É£ Installazione dipendenze

```bash
pip install -r requirements.txt --no-build-isolation
```

4Ô∏è‚É£ Avvio server Flask

```bash
python app.py
```

Backend disponibile su:

```
http://127.0.0.1:5000
```

---

## Team

| Nome               | GitHub                                       |
| ------------------ | -------------------------------------------- |
| üë® `Di Vita Marco` | [Click here](https://github.com/divitamarco) |

---

